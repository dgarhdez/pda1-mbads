{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Session 13: Introduction to Pandas and Reading Data\n",
    "\n",
    "Welcome to the world of **Pandas**! This library is the cornerstone of data analysis in Python. In this session, we'll learn what Pandas is, how to create and explore DataFrames, and how to read data from files.\n",
    "\n",
    "## Learning Objectives\n",
    "\n",
    "By the end of this session, you will be able to:\n",
    "- Explain what Pandas is and why it's essential for data analysis\n",
    "- Create Series and DataFrames from Python data structures\n",
    "- Inspect DataFrames using basic properties and methods\n",
    "- Read data from CSV and JSON files\n",
    "- Save DataFrames to files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. What is Pandas and Why Use It?\n",
    "\n",
    "**Pandas** is a powerful Python library for data manipulation and analysis. The name comes from \"Panel Data\" (an econometrics term) and \"Python Data Analysis\".\n",
    "\n",
    "### Why Pandas?\n",
    "\n",
    "- **Efficient data structures**: DataFrames and Series make working with tabular data intuitive\n",
    "- **Data cleaning**: Built-in tools for handling missing values, duplicates, and data type conversions\n",
    "- **Data manipulation**: Easy filtering, grouping, merging, and reshaping\n",
    "- **File I/O**: Read and write data from various formats (CSV, Excel, JSON, SQL, etc.)\n",
    "- **Integration**: Works seamlessly with NumPy, Matplotlib, and other data science libraries\n",
    "\n",
    "### Installing and Importing Pandas\n",
    "\n",
    "Pandas is typically installed via pip: `pip install pandas`\n",
    "\n",
    "The convention is to import it with the alias `pd`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import pandas as pd\n\n# Check the version\npd.__version__"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Series: The Building Block\n",
    "\n",
    "A **Series** is a one-dimensional labeled array. Think of it as a single column of data with an index.\n",
    "\n",
    "### Creating a Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Creating a Series from a list\ngrades = pd.Series([85, 90, 78, 92, 88])\ngrades"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Creating a Series with custom index\ngrades = pd.Series(\n    [85, 90, 78, 92, 88],\n    index=['Alice', 'Bob', 'Charlie', 'Diana', 'Eve']\n)\ngrades"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Creating a Series from a dictionary\npopulation = pd.Series({\n    'Madrid': 3_223_000,\n    'Barcelona': 1_620_000,\n    'Valencia': 791_000,\n    'Seville': 688_000\n})\npopulation"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Accessing elements in a Series\ngrades['Bob'], grades[0], grades[grades > 85]"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Series Attributes and Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "grades.values, grades.index.tolist(), grades.dtype, grades.size, grades.mean()"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. DataFrames: The Star of the Show\n",
    "\n",
    "A **DataFrame** is a two-dimensional labeled data structure with columns of potentially different types. Think of it as a spreadsheet or SQL table.\n",
    "\n",
    "### Creating DataFrames from Dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a DataFrame from a dictionary of lists\n",
    "# Each key becomes a column name, each list becomes the column values\n",
    "\n",
    "students = pd.DataFrame({\n",
    "    'name': ['Alice', 'Bob', 'Charlie', 'Diana', 'Eve'],\n",
    "    'age': [22, 25, 23, 24, 22],\n",
    "    'major': ['Economics', 'Computer Science', 'Economics', 'Finance', 'Marketing'],\n",
    "    'gpa': [3.8, 3.5, 3.2, 3.9, 3.6]\n",
    "})\n",
    "\n",
    "students"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a DataFrame from a list of dictionaries\n",
    "# Each dictionary represents a row\n",
    "\n",
    "products = pd.DataFrame([\n",
    "    {'product': 'Laptop', 'price': 999.99, 'stock': 50},\n",
    "    {'product': 'Mouse', 'price': 29.99, 'stock': 200},\n",
    "    {'product': 'Keyboard', 'price': 79.99, 'stock': 150},\n",
    "    {'product': 'Monitor', 'price': 299.99, 'stock': 75}\n",
    "])\n",
    "\n",
    "products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a DataFrame with a custom index\n",
    "sales = pd.DataFrame(\n",
    "    {\n",
    "        'units_sold': [150, 200, 175, 225],\n",
    "        'revenue': [15000, 20000, 17500, 22500]\n",
    "    },\n",
    "    index=['Q1', 'Q2', 'Q3', 'Q4']\n",
    ")\n",
    "\n",
    "sales"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating DataFrames from Lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From a list of lists (need to specify column names)\n",
    "data = [\n",
    "    ['Madrid', 'Spain', 3223000],\n",
    "    ['Barcelona', 'Spain', 1620000],\n",
    "    ['Lisbon', 'Portugal', 545000],\n",
    "    ['Porto', 'Portugal', 238000]\n",
    "]\n",
    "\n",
    "cities = pd.DataFrame(data, columns=['city', 'country', 'population'])\n",
    "cities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Basic DataFrame Properties\n",
    "\n",
    "Once you have a DataFrame, you'll want to understand its structure. Here are the essential properties:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's create a larger dataset for demonstration\n",
    "employees = pd.DataFrame({\n",
    "    'employee_id': [101, 102, 103, 104, 105, 106, 107, 108],\n",
    "    'name': ['Ana Garcia', 'Carlos Lopez', 'Maria Santos', 'Juan Martinez', \n",
    "             'Laura Fernandez', 'Pedro Gonzalez', 'Sofia Rodriguez', 'Diego Hernandez'],\n",
    "    'department': ['Sales', 'IT', 'HR', 'Sales', 'IT', 'Marketing', 'HR', 'Sales'],\n",
    "    'salary': [45000, 55000, 48000, 52000, 60000, 47000, 46000, 49000],\n",
    "    'years_experience': [3, 5, 4, 6, 7, 2, 3, 4],\n",
    "    'is_manager': [False, True, False, True, True, False, False, False]\n",
    "})\n",
    "\n",
    "employees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Shape: (rows, columns)\nemployees.shape, employees.shape[0], employees.shape[1]"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Column names\nemployees.columns, employees.columns.tolist()"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Data types of each column\nemployees.dtypes"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# The info() method: comprehensive summary\nemployees.info()"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Index\nemployees.index, employees.index.tolist()"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Viewing Data: head(), tail(), sample()\n",
    "\n",
    "With large datasets, you don't want to display everything. These methods let you peek at the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# head() - first n rows (default 5)\nemployees.head(3)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# tail() - last n rows (default 5)\nemployees.tail(3)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# sample() - random rows\nemployees.sample(3)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# sample() with random_state for reproducibility\nemployees.sample(3, random_state=42)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Basic Statistics with describe()\n",
    "\n",
    "The `describe()` method provides summary statistics for numerical columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary statistics for numerical columns\n",
    "employees.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Include all columns (including non-numeric)\n",
    "employees.describe(include='all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Reading Data from Files\n",
    "\n",
    "Real-world data usually comes from files. Pandas makes reading data incredibly easy.\n",
    "\n",
    "### Reading CSV Files\n",
    "\n",
    "CSV (Comma-Separated Values) is the most common format for tabular data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# First, let's create a sample CSV file to work with\nsample_data = pd.DataFrame({\n    'date': ['2024-01-15', '2024-01-16', '2024-01-17', '2024-01-18', '2024-01-19'],\n    'product': ['Widget A', 'Widget B', 'Widget A', 'Widget C', 'Widget B'],\n    'quantity': [10, 5, 8, 12, 7],\n    'unit_price': [25.99, 15.50, 25.99, 35.00, 15.50],\n    'customer': ['Acme Corp', 'TechStart', 'Acme Corp', 'BigRetail', 'TechStart']\n})\n\n# Save to CSV\nsample_data.to_csv('sales_data.csv', index=False)\n\"Sample CSV file created!\""
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading a CSV file\n",
    "df = pd.read_csv('sales_data.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Common read_csv parameters\n\n# sep: specify delimiter (default is comma)\n# df = pd.read_csv('file.csv', sep=';')  # for semicolon-separated\n\n# header: row number to use as column names (default 0)\n# df = pd.read_csv('file.csv', header=None)  # no header row\n\n# names: provide column names\n# df = pd.read_csv('file.csv', names=['col1', 'col2', 'col3'])\n\n# usecols: read only specific columns\ndf_subset = pd.read_csv('sales_data.csv', usecols=['date', 'product', 'quantity'])\ndf_subset"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# nrows: read only first n rows (useful for large files)\ndf_preview = pd.read_csv('sales_data.csv', nrows=3)\ndf_preview"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# index_col: use a column as the index\ndf_indexed = pd.read_csv('sales_data.csv', index_col='date')\ndf_indexed"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading JSON Files\n",
    "\n",
    "JSON is common for web APIs and modern data exchange."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Create a sample JSON file\nimport json\n\njson_data = [\n    {\"name\": \"Python for Data Analysis\", \"author\": \"Wes McKinney\", \"year\": 2022, \"price\": 49.99},\n    {\"name\": \"Hands-On Machine Learning\", \"author\": \"Aurelien Geron\", \"year\": 2022, \"price\": 59.99},\n    {\"name\": \"Deep Learning\", \"author\": \"Ian Goodfellow\", \"year\": 2016, \"price\": 72.00},\n    {\"name\": \"The Pragmatic Programmer\", \"author\": \"David Thomas\", \"year\": 2019, \"price\": 49.99}\n]\n\nwith open('books.json', 'w') as f:\n    json.dump(json_data, f, indent=2)\n    \n\"Sample JSON file created!\""
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading JSON\n",
    "books = pd.read_json('books.json')\n",
    "books"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# JSON can have different orientations\n",
    "# Let's create a records-oriented JSON\n",
    "records_json = '{\"name\":{\"0\":\"Alice\",\"1\":\"Bob\"},\"age\":{\"0\":25,\"1\":30}}'\n",
    "\n",
    "with open('records.json', 'w') as f:\n",
    "    f.write(records_json)\n",
    "\n",
    "# Reading with different orient\n",
    "df_records = pd.read_json('records.json', orient='columns')\n",
    "df_records"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Handling File Issues\n",
    "\n",
    "Real-world files often have issues. Here's how to handle common problems:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Create a problematic CSV file\nproblematic_csv = \"\"\"name;age;salary\nAlice;25;50000\nBob;30;N/A\nCharlie;-;55000\nDiana;28;52000\"\"\"\n\nwith open('problematic.csv', 'w') as f:\n    f.write(problematic_csv)\n    \n\"Problematic CSV created!\""
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle different delimiter\n",
    "df = pd.read_csv('problematic.csv', sep=';')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle custom missing values\n",
    "df = pd.read_csv('problematic.csv', sep=';', na_values=['N/A', '-', 'NA', 'null'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Check for missing values\ndf.isnull().sum()"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handling encoding issues (common with international characters)\n",
    "# Create a file with special characters\n",
    "special_chars = \"\"\"ciudad,poblacion\n",
    "Madrid,3223000\n",
    "Malaga,571000\n",
    "Coruna,245000\"\"\"\n",
    "\n",
    "with open('ciudades.csv', 'w', encoding='utf-8') as f:\n",
    "    f.write(special_chars)\n",
    "\n",
    "# Read with proper encoding\n",
    "ciudades = pd.read_csv('ciudades.csv', encoding='utf-8')\n",
    "ciudades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Handling file not found errors\nimport os\n\nfilename = 'nonexistent.csv'\n\nif os.path.exists(filename):\n    df = pd.read_csv(filename)\nelse:\n    f\"File '{filename}' not found!\""
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using try/except for robust file reading\n",
    "try:\n",
    "    df = pd.read_csv('nonexistent.csv')\n",
    "except FileNotFoundError:\n",
    "    print(\"File not found! Please check the path.\")\n",
    "except pd.errors.EmptyDataError:\n",
    "    print(\"File is empty!\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Saving DataFrames\n",
    "\n",
    "After processing data, you'll often want to save the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a sample DataFrame to save\n",
    "results = pd.DataFrame({\n",
    "    'student': ['Alice', 'Bob', 'Charlie'],\n",
    "    'score': [95, 87, 92],\n",
    "    'passed': [True, True, True]\n",
    "})\n",
    "\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Save to CSV\nresults.to_csv('results.csv', index=False)  # index=False prevents saving the index\n\n# Verify by reading it back\npd.read_csv('results.csv')"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Save to CSV with custom separator\nresults.to_csv('results_semicolon.csv', sep=';', index=False)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Save to JSON\nresults.to_json('results.json', orient='records', indent=2)\n\n# Let's see what it looks like\nwith open('results.json', 'r') as f:\n    f.read()"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to Excel (requires openpyxl: pip install openpyxl)\n",
    "try:\n",
    "    results.to_excel('results.xlsx', index=False, sheet_name='Scores')\n",
    "    print(\"Saved to results.xlsx\")\n",
    "except ModuleNotFoundError:\n",
    "    print(\"openpyxl not installed. Run: pip install openpyxl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Accessing Columns\n",
    "\n",
    "A quick preview of how to access individual columns (we'll cover this in depth next session):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Access a single column (returns a Series)\nemployees['name']"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Access using dot notation (only works for column names without spaces)\nemployees.salary"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Access multiple columns (returns a DataFrame)\nemployees[['name', 'salary']]"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new column\n",
    "employees['bonus'] = employees['salary'] * 0.1\n",
    "employees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this session, we covered:\n",
    "\n",
    "1. **What Pandas is**: A powerful library for data manipulation and analysis\n",
    "2. **Series**: One-dimensional labeled arrays\n",
    "3. **DataFrames**: Two-dimensional labeled data structures (the main workhorse)\n",
    "4. **Creating DataFrames**: From dictionaries and lists\n",
    "5. **Basic properties**: `shape`, `columns`, `dtypes`, `info()`\n",
    "6. **Viewing data**: `head()`, `tail()`, `sample()`\n",
    "7. **Statistics**: `describe()`\n",
    "8. **Reading files**: `read_csv()`, `read_json()`\n",
    "9. **Handling issues**: Delimiters, missing values, encoding\n",
    "10. **Saving data**: `to_csv()`, `to_json()`, `to_excel()`\n",
    "\n",
    "### Key Points to Remember\n",
    "\n",
    "- Import pandas as: `import pandas as pd`\n",
    "- A DataFrame is like a spreadsheet: rows and columns\n",
    "- Always check your data with `head()`, `info()`, and `describe()`\n",
    "- `read_csv()` and `to_csv()` are your most common file operations\n",
    "- Use `index=False` when saving to avoid extra index columns\n",
    "\n",
    "### Next Session\n",
    "\n",
    "We'll practice everything we learned today with hands-on exercises!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Cleanup: remove the temporary files we created\nimport os\n\nfiles_to_remove = [\n    'sales_data.csv', 'books.json', 'records.json', \n    'problematic.csv', 'ciudades.csv', 'results.csv', \n    'results_semicolon.csv', 'results.json', 'results.xlsx'\n]\n\nfor file in files_to_remove:\n    if os.path.exists(file):\n        os.remove(file)\n        \n\"Temporary files cleaned up!\""
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}